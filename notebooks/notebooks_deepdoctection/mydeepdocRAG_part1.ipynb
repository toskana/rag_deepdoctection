{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61b357cd-8082-4b24-ac97-dc6b3835f48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf7b642-0cf6-4dfe-8914-f4cfb7f797d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0721 13:27.24 @file_utils.py:31]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mPyTorch version 1.13.1+cu117 available.\u001b[0m\n",
      "\u001b[32m[0721 13:27.24 @file_utils.py:69]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mDisabling Tensorflow because USE_TORCH is set\u001b[0m\n",
      "\u001b[32m[0721 13:27.25 @font_manager.py:1639]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mgenerated new fontManager\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import deepdoctection as dd\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "51c544de-d914-495b-b684-35d793d9b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_pages_data(pages_data, max_pages=2, max_chunks=3, max_text_len=1000, max_rows=50, max_cols=10):\n",
    "    print(f\"Anzahl Seiten: {len(pages_data)}\")\n",
    "    if len(pages_data) == 0:\n",
    "        print(\"Keine Seiten im Datenobjekt.\")\n",
    "        return\n",
    "\n",
    "    for i, page in enumerate(pages_data[:max_pages]):\n",
    "        print(f\"\\n=== Seite {i+1} ===\")\n",
    "        print(f\"Typ: {type(page)}\")\n",
    "        print(f\"Keys: {list(page.keys())}\")\n",
    "        print(f\"Seiten-Nummer: {page.get('page_number')}\")\n",
    "        print(f\"Dateiname: {page.get('file_name')}\")\n",
    "        print(f\"Text (erste {max_text_len} Zeichen): {page.get('text', '')[:max_text_len]!r}\")\n",
    "\n",
    "        chunks = page.get(\"chunks\", [])\n",
    "        print(f\"Anzahl Chunks: {len(chunks)}\")\n",
    "        for j, chunk in enumerate(chunks[:max_chunks]):\n",
    "            if isinstance(chunk, tuple) and len(chunk) == 2:\n",
    "                bbox, text = chunk\n",
    "                print(f\"  Chunk {j+1}: bbox={bbox}, text={text[:max_text_len]!r}\")\n",
    "            else:\n",
    "                print(f\"  Chunk {j+1}: {str(chunk)[:max_text_len]!r}\")\n",
    "\n",
    "        tables = page.get(\"tables\", [])\n",
    "        print(f\"Anzahl Tabellen: {len(tables)}\")\n",
    "        for k, table in enumerate(tables):\n",
    "            print(f\"\\n  Tabelle {k+1}: Typ={type(table)} Größe={table.shape if hasattr(table, 'shape') else 'unbekannt'}\")\n",
    "            if hasattr(table, \"head\"):\n",
    "                # Ausgabe der ersten max_rows Zeilen, max_cols Spalten, als Text\n",
    "                print(table.iloc[:max_rows, :max_cols].to_string(index=False))\n",
    "            else:\n",
    "                print(str(table)[:max_text_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8296fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_to_dataframe(table) -> pd.DataFrame:\n",
    "    \"\"\"Konvertiert eine DeepDoctection-Tabelle in ein Pandas-DataFrame.\"\"\"\n",
    "    n_rows = table.number_of_rows\n",
    "    n_cols = table.number_of_columns\n",
    "    cells = table.cells\n",
    "\n",
    "    cell_map = {}\n",
    "    for cell in cells:\n",
    "        r = getattr(cell, \"row_number\", None)\n",
    "        c = getattr(cell, \"column_number\", None)\n",
    "        text = getattr(cell, \"text\", \"\")\n",
    "        if r is not None and c is not None:\n",
    "            cell_map[(r, c)] = text\n",
    "\n",
    "    rows = []\n",
    "    for r in range(n_rows):\n",
    "        row = []\n",
    "        for c in range(n_cols):\n",
    "            row.append(cell_map.get((r, c), \"\"))\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c73284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page_data(page) -> Dict[str, Any]:\n",
    "    \"\"\"Extrahiert alle wichtigen Inhalte aus einer einzelnen Seite.\"\"\"\n",
    "    page_info = {\n",
    "        \"page_number\": page.page_number,\n",
    "        \"file_name\": page.file_name,\n",
    "        \"document_id\": page.document_id,\n",
    "        \"image_id\": page.image_id,\n",
    "        \"width\": page.width,\n",
    "        \"height\": page.height,\n",
    "        \"text\": page.text,\n",
    "        \"chunks\": [],\n",
    "        \"tables\": []\n",
    "    }\n",
    "\n",
    "    # Text-Chunks (aus Layoutanalyse)\n",
    "    if page.chunks:\n",
    "        for chunk in page.chunks:\n",
    "            if isinstance(chunk, tuple) and len(chunk) == 2:\n",
    "                bbox, text = chunk\n",
    "                page_info[\"chunks\"].append({\n",
    "                    \"bbox\": bbox,\n",
    "                    \"text\": text\n",
    "                })\n",
    "\n",
    "    # Tabellen als DataFrames\n",
    "    if page.tables:\n",
    "        for table in page.tables:\n",
    "            df_table = table_to_dataframe(table)\n",
    "            page_info[\"tables\"].append(df_table)\n",
    "\n",
    "    return page_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6771e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pdf(path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Analysiert das PDF und liefert eine Liste von Seiteninformationen.\"\"\"\n",
    "    analyzer = dd.get_dd_analyzer()\n",
    "    df = analyzer.analyze(path=path)\n",
    "\n",
    "    pages = []\n",
    "    for page in df:\n",
    "        page_data = extract_page_data(page)\n",
    "        pages.append(page_data)\n",
    "\n",
    "    df.reset_state()\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adcdc30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_pages_data_as_json(pages_data, output_file):\n",
    "    output = []\n",
    "    for page in pages_data:\n",
    "        page_entry = {\n",
    "            \"page_number\": page.get(\"page_number\"),\n",
    "            \"file_name\": page.get(\"file_name\"),\n",
    "            \"document_id\": page.get(\"document_id\"),\n",
    "            \"image_id\": page.get(\"image_id\"),\n",
    "            \"width\": page.get(\"width\"),\n",
    "            \"height\": page.get(\"height\"),\n",
    "            \"text\": page.get(\"text\"),\n",
    "            \"tables\": []\n",
    "        }\n",
    "\n",
    "        for df in page.get(\"tables\", []):\n",
    "            csv_str = df.to_csv(index=False)\n",
    "            page_entry[\"tables\"].append(csv_str)\n",
    "\n",
    "        output.append(page_entry)\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36fcfa8c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0721 12:24.48 @dd.py:129]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mConfig: \n",
      " {'DEVICE': device(type='cpu'),\n",
      " 'LANGUAGE': None,\n",
      " 'LAYOUT_LINK': {'CHILD_CATEGORIES': [<LayoutType.CAPTION>],\n",
      "                 'PARENTAL_CATEGORIES': [<LayoutType.FIGURE>, <LayoutType.TABLE>]},\n",
      " 'LAYOUT_NMS_PAIRS': {'COMBINATIONS': [[<LayoutType.TABLE>, <LayoutType.TITLE>],\n",
      "                                       [<LayoutType.TABLE>, <LayoutType.TEXT>],\n",
      "                                       [<LayoutType.TABLE>, <LayoutType.KEY_VALUE_AREA>],\n",
      "                                       [<LayoutType.TABLE>, <LayoutType.LIST_ITEM>],\n",
      "                                       [<LayoutType.TABLE>, <LayoutType.LIST>],\n",
      "                                       [<LayoutType.TABLE>, <LayoutType.FIGURE>],\n",
      "                                       [<LayoutType.TITLE>, <LayoutType.TEXT>],\n",
      "                                       [<LayoutType.TEXT>, <LayoutType.KEY_VALUE_AREA>],\n",
      "                                       [<LayoutType.TEXT>, <LayoutType.LIST_ITEM>],\n",
      "                                       [<LayoutType.TEXT>, <LayoutType.CAPTION>],\n",
      "                                       [<LayoutType.KEY_VALUE_AREA>, <LayoutType.LIST_ITEM>],\n",
      "                                       [<LayoutType.FIGURE>, <LayoutType.CAPTION>]],\n",
      "                      'PRIORITY': [<LayoutType.TABLE>, <LayoutType.TABLE>, <LayoutType.TABLE>,\n",
      "                                   <LayoutType.TABLE>, <LayoutType.TABLE>, <LayoutType.TABLE>,\n",
      "                                   <LayoutType.TEXT>, <LayoutType.TEXT>, None, <LayoutType.CAPTION>,\n",
      "                                   <LayoutType.KEY_VALUE_AREA>, <LayoutType.FIGURE>],\n",
      "                      'THRESHOLDS': [0.001, 0.01, 0.01, 0.001, 0.01, 0.01, 0.05, 0.01, 0.01, 0.01,\n",
      "                                     0.01, 0.001]},\n",
      " 'LIB': 'PT',\n",
      " 'OCR': {'CONFIG': {'TESSERACT': 'dd/conf_tesseract.yaml'},\n",
      "         'USE_DOCTR': True,\n",
      "         'USE_TESSERACT': False,\n",
      "         'USE_TEXTRACT': False,\n",
      "         'WEIGHTS': {'DOCTR_RECOGNITION': {'PT': 'doctr/crnn_vgg16_bn/pt/crnn_vgg16_bn-9762b0b0.pt',\n",
      "                                           'TF': 'doctr/crnn_vgg16_bn/tf/crnn_vgg16_bn-76b7f2c6.zip'},\n",
      "                     'DOCTR_WORD': {'PT': 'doctr/db_resnet50/pt/db_resnet50-ac60cadc.pt',\n",
      "                                    'TF': 'doctr/db_resnet50/tf/db_resnet50-adcafc63.zip'}}},\n",
      " 'PDF_MINER': {'X_TOLERANCE': 3, 'Y_TOLERANCE': 3},\n",
      " 'PT': {'CELL': {'FILTER': None,\n",
      "                 'PAD': {'BOTTOM': 60, 'LEFT': 60, 'RIGHT': 60, 'TOP': 60},\n",
      "                 'PADDING': False,\n",
      "                 'WEIGHTS': 'cell/d2_model_1849999_cell_inf_only.pt',\n",
      "                 'WEIGHTS_TS': 'cell/d2_model_1849999_cell_inf_only.ts'},\n",
      "        'ENFORCE_WEIGHTS': {'CELL': False, 'ITEM': False, 'LAYOUT': False},\n",
      "        'ITEM': {'FILTER': ['table'],\n",
      "                 'PAD': {'BOTTOM': 60, 'LEFT': 60, 'RIGHT': 60, 'TOP': 60},\n",
      "                 'PADDING': False,\n",
      "                 'WEIGHTS': 'deepdoctection/tatr_tab_struct_v2/pytorch_model.bin',\n",
      "                 'WEIGHTS_TS': 'item/d2_model_1639999_item_inf_only.ts'},\n",
      "        'LAYOUT': {'FILTER': None,\n",
      "                   'PAD': {'BOTTOM': 0, 'LEFT': 0, 'RIGHT': 0, 'TOP': 0},\n",
      "                   'PADDING': False,\n",
      "                   'WEIGHTS': 'Aryn/deformable-detr-DocLayNet/model.safetensors',\n",
      "                   'WEIGHTS_TS': 'layout/d2_model_0829999_layout_inf_only.ts'}},\n",
      " 'SEGMENTATION': {'ASSIGNMENT_RULE': 'ioa',\n",
      "                  'CELL_NAMES': [<CellType.HEADER>, <CellType.BODY>, <LayoutType.CELL>],\n",
      "                  'FULL_TABLE_TILING': True,\n",
      "                  'ITEM_NAMES': [<LayoutType.ROW>, <LayoutType.COLUMN>],\n",
      "                  'PUBTABLES_CELL_NAMES': [<LayoutType.CELL>],\n",
      "                  'PUBTABLES_ITEM_HEADER_CELL_NAMES': [<CellType.COLUMN_HEADER>,\n",
      "                                                       <CellType.ROW_HEADER>,\n",
      "                                                       <CellType.PROJECTED_ROW_HEADER>],\n",
      "                  'PUBTABLES_ITEM_HEADER_THRESHOLDS': [0.6, 0.0001],\n",
      "                  'PUBTABLES_ITEM_NAMES': [<LayoutType.ROW>, <LayoutType.COLUMN>],\n",
      "                  'PUBTABLES_SPANNING_CELL_NAMES': [<CellType.SPANNING>],\n",
      "                  'PUBTABLES_SUB_ITEM_NAMES': [<CellType.ROW_NUMBER>, <CellType.COLUMN_NUMBER>],\n",
      "                  'REMOVE_IOU_THRESHOLD_COLS': 0.2,\n",
      "                  'REMOVE_IOU_THRESHOLD_ROWS': 0.2,\n",
      "                  'STRETCH_RULE': 'equal',\n",
      "                  'SUB_ITEM_NAMES': [<CellType.ROW_NUMBER>, <CellType.COLUMN_NUMBER>],\n",
      "                  'TABLE_NAME': <LayoutType.TABLE>,\n",
      "                  'THRESHOLD_COLS': 0.4,\n",
      "                  'THRESHOLD_ROWS': 0.4},\n",
      " 'TEXT_CONTAINER': <LayoutType.WORD>,\n",
      " 'TEXT_ORDERING': {'BROKEN_LINE_TOLERANCE': 0.003,\n",
      "                   'FLOATING_TEXT_BLOCK_CATEGORIES': (<LayoutType.TEXT>, <LayoutType.TITLE>,\n",
      "                                                      <LayoutType.LIST>,\n",
      "                                                      <LayoutType.KEY_VALUE_AREA>),\n",
      "                   'HEIGHT_TOLERANCE': 2.0,\n",
      "                   'INCLUDE_RESIDUAL_TEXT_CONTAINER': True,\n",
      "                   'PARAGRAPH_BREAK': 0.035,\n",
      "                   'STARTING_POINT_TOLERANCE': 0.005,\n",
      "                   'TEXT_BLOCK_CATEGORIES': (<LayoutType.TEXT>, <LayoutType.TITLE>,\n",
      "                                             <LayoutType.LIST_ITEM>, <LayoutType.LIST>,\n",
      "                                             <LayoutType.CAPTION>, <LayoutType.PAGE_HEADER>,\n",
      "                                             <LayoutType.PAGE_FOOTER>, <LayoutType.PAGE_NUMBER>,\n",
      "                                             <LayoutType.MARK>, <LayoutType.KEY_VALUE_AREA>,\n",
      "                                             <LayoutType.FIGURE>, <CellType.SPANNING>,\n",
      "                                             <LayoutType.CELL>)},\n",
      " 'TF': {'CELL': {'FILTER': None, 'WEIGHTS': 'cell/model-1800000_inf_only.data-00000-of-00001'},\n",
      "        'ITEM': {'FILTER': None, 'WEIGHTS': 'item/model-1620000_inf_only.data-00000-of-00001'},\n",
      "        'LAYOUT': {'FILTER': None, 'WEIGHTS': 'layout/model-800000_inf_only.data-00000-of-00001'}},\n",
      " 'USE_LAYOUT': True,\n",
      " 'USE_LAYOUT_LINK': False,\n",
      " 'USE_LAYOUT_NMS': True,\n",
      " 'USE_LINE_MATCHER': False,\n",
      " 'USE_OCR': True,\n",
      " 'USE_PDF_MINER': False,\n",
      " 'USE_ROTATOR': False,\n",
      " 'USE_TABLE_REFINEMENT': False,\n",
      " 'USE_TABLE_SEGMENTATION': True,\n",
      " 'WORD_MATCHING': {'MAX_PARENT_ONLY': True,\n",
      "                   'PARENTAL_CATEGORIES': (<LayoutType.TEXT>, <LayoutType.TITLE>,\n",
      "                                           <LayoutType.LIST_ITEM>, <LayoutType.LIST>,\n",
      "                                           <LayoutType.CAPTION>, <LayoutType.PAGE_HEADER>,\n",
      "                                           <LayoutType.PAGE_FOOTER>, <LayoutType.PAGE_NUMBER>,\n",
      "                                           <LayoutType.MARK>, <LayoutType.KEY_VALUE_AREA>,\n",
      "                                           <LayoutType.FIGURE>, <CellType.SPANNING>,\n",
      "                                           <LayoutType.CELL>),\n",
      "                   'RULE': 'ioa',\n",
      "                   'THRESHOLD': 0.3}}\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:937: FutureWarning: The `force_filename` parameter is deprecated as a new caching system, which keeps the filenames as they are on the Hub, is now in place.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40feb2502734aa88283fcc8b3fef7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "d2_model_0829999_layout_inf_only.ts:   0%|          | 0.00/275M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0721 12:25.11 @model.py:452]\u001b[0m  \u001b[4m\u001b[5m\u001b[31mERR\u001b[0m  \u001b[97mFile downloaded from deepdoctection/d2_casc_rcnn_X_32xd4_50_FPN_GN_2FC_publaynet_inference_only does not match the expected size! You may have downloaded a broken file, or the upstream may have modified the file.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a17f5839e8459783d049b836b8cf22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CASCADE_RCNN_R_50_FPN_GN_TS.yaml:   0%|          | 0.00/143 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319ecdccd0cd4406b409274107c869e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "d2_model_1639999_item_inf_only.ts:   0%|          | 0.00/275M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0721 12:25.35 @model.py:452]\u001b[0m  \u001b[4m\u001b[5m\u001b[31mERR\u001b[0m  \u001b[97mFile downloaded from deepdoctection/d2_casc_rcnn_X_32xd4_50_FPN_GN_2FC_pubtabnet_rc_inference_only does not match the expected size! You may have downloaded a broken file, or the upstream may have modified the file.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398cdce5afff4261bcf75c0dedd2a037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CASCADE_RCNN_R_50_FPN_GN_TS.yaml:   0%|          | 0.00/143 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b657070e914f41cbbdd3b3cf4898b04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "d2_model_1849999_cell_inf_only.ts:   0%|          | 0.00/275M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0721 12:25.59 @model.py:452]\u001b[0m  \u001b[4m\u001b[5m\u001b[31mERR\u001b[0m  \u001b[97mFile downloaded from deepdoctection/d2_casc_rcnn_X_32xd4_50_FPN_GN_2FC_pubtabnet_c_inference_only does not match the expected size! You may have downloaded a broken file, or the upstream may have modified the file.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef44afc85d448a5a3a69a150662b86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CASCADE_RCNN_R_50_FPN_GN_TS.yaml:   0%|          | 0.00/141 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0721 12:26.00 @fs.py:142]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mFile db_resnet50-ac60cadc.pt will be downloaded.\u001b[0m\n",
      "db_resnet50-ac60cadc.pt: |          |102M/?[00:10<00:00,10.1MB/s]\n",
      "\u001b[32m[0721 12:26.10 @fs.py:171]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mSuccessfully downloaded db_resnet50-ac60cadc.pt. 97.2MiB.\u001b[0m\n",
      "\u001b[32m[0721 12:26.11 @fs.py:142]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mFile crnn_vgg16_bn-9762b0b0.pt will be downloaded.\u001b[0m\n",
      "crnn_vgg16_bn-9762b0b0.pt: |          |63.3M/?[00:06<00:00,10.2MB/s]\n",
      "\u001b[32m[0721 12:26.17 @fs.py:171]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mSuccessfully downloaded crnn_vgg16_bn-9762b0b0.pt. 60.4MiB.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://doctr-static.mindee.com/models?id=v0.3.1/crnn_vgg16_bn-9762b0b0.pt&src=0 to /root/.cache/doctr/models/crnn_vgg16_bn-9762b0b0.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9502a899709c410fb2f0b4a56cb56464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63286381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0721 12:26.25 @data.py:92]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mUsing downloaded & verified file: /root/.cache/doctr/models/crnn_vgg16_bn-9762b0b0.pt\u001b[0m\n",
      "\u001b[32m[0721 12:26.25 @order.py:805]\u001b[0m  \u001b[5m\u001b[35mWRN\u001b[0m  \u001b[97mIn most cases floating_text_block_categories must be a subset of text_block_categories. Adding categories to floating_text_block_categories, that do not belong to text_block_categories makes only sense for categories set have CHILD relationships with annotations that belong to text_block_categories.\u001b[0m\n",
      "\u001b[32m[0721 12:26.25 @doctectionpipe.py:118]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mProcessing 2024-nachhaltigkeitsbericht_tab_0.pdf\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1194: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return forward_call(*input, **kwargs)\n",
      "\u001b[32m[0721 12:26.27 @context.py:154]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mImageLayoutService total: 1.763 sec.\u001b[0m\n",
      "\u001b[32m[0721 12:26.27 @context.py:154]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mAnnotationNmsService total: 0.0007 sec.\u001b[0m\n",
      "\u001b[32m[0721 12:26.29 @context.py:154]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mSubImageLayoutService total: 2.1039 sec.\u001b[0m\n",
      "\u001b[32m[0721 12:26.31 @context.py:154]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mSubImageLayoutService total: 1.7958 sec.\u001b[0m\n",
      "\u001b[32m[0721 12:26.31 @context.py:154]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mTableSegmentationService total: 0.041 sec.\u001b[0m\n",
      "\u001b[32m[0721 12:26.32 @context.py:154]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mImageLayoutService total: 0.839 sec.\u001b[0m\n",
      "\u001b[32m[0721 12:26.33 @context.py:154]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mTextExtractionService total: 1.6126 sec.\u001b[0m\n",
      "\u001b[32m[0721 12:26.33 @context.py:154]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mMatchingService total: 0.0039 sec.\u001b[0m\n",
      "\u001b[32m[0721 12:26.33 @context.py:154]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mTextOrderService total: 0.0423 sec.\u001b[0m\n",
      "\u001b[32m[0721 12:26.34 @doctectionpipe.py:118]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mProcessing 2024-nachhaltigkeitsbericht_tab_1.pdf\u001b[0m\n",
      "\u001b[32m[0721 12:26.37 @context.py:154]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mImageLayoutService total: 2.7538 sec.\u001b[0m\n",
      "\u001b[32m[0721 12:26.37 @context.py:154]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mAnnotationNmsService total: 0.001 sec.\u001b[0m\n",
      "\u001b[32m[0721 12:26.40 @context.py:154]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mSubImageLayoutService total: 2.9726 sec.\u001b[0m\n",
      "\u001b[32m[0721 12:26.42 @context.py:154]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mSubImageLayoutService total: 2.654 sec.\u001b[0m\n",
      "\u001b[32m[0721 12:26.42 @context.py:154]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mTableSegmentationService total: 0.0323 sec.\u001b[0m\n",
      "\u001b[32m[0721 12:26.43 @context.py:154]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mImageLayoutService total: 0.8127 sec.\u001b[0m\n",
      "\u001b[32m[0721 12:26.45 @context.py:154]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mTextExtractionService total: 1.9093 sec.\u001b[0m\n",
      "\u001b[32m[0721 12:26.45 @context.py:154]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mMatchingService total: 0.0057 sec.\u001b[0m\n",
      "\u001b[32m[0721 12:26.45 @context.py:154]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mTextOrderService total: 0.0571 sec.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Seiten analysiert.\n"
     ]
    }
   ],
   "source": [
    "PDF_PATH = \"/repo/notebooks/data/2024-nachhaltigkeitsbericht_tab.pdf\"\n",
    "pages_data = list(analyze_pdf(PDF_PATH))\n",
    "print(f\"{len(pages_data)} Seiten analysiert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dc8c661",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Seiten: 2\n",
      "\n",
      "=== Seite 1 ===\n",
      "Typ: <class 'dict'>\n",
      "Keys: ['page_number', 'file_name', 'document_id', 'image_id', 'width', 'height', 'text', 'chunks', 'tables']\n",
      "Seiten-Nummer: 0\n",
      "Dateiname: 2024-nachhaltigkeitsbericht_tab_0.pdf\n",
      "Text (erste 100 Zeichen): 'HENKEL NACHHALTIGKEITSBERICHT 2024\\n( QB\\n161\\nVORWORT\\nREFERENZ- UND\\nBERICHTSRAHMEN\\nALLGEMEINE ANGABEN\\n'\n",
      "Anzahl Chunks: 0\n",
      "Anzahl Tabellen: 1\n",
      "  Tabelle 1: Typ=<class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "=== Seite 2 ===\n",
      "Typ: <class 'dict'>\n",
      "Keys: ['page_number', 'file_name', 'document_id', 'image_id', 'width', 'height', 'text', 'chunks', 'tables']\n",
      "Seiten-Nummer: 1\n",
      "Dateiname: 2024-nachhaltigkeitsbericht_tab_1.pdf\n",
      "Text (erste 100 Zeichen): 'HENKEL NACHHALTIGKEITSBERICHT 2024\\n( QB\\n168\\nVORWORT\\nREFERENZ- UND\\nBERICHTSRAHMEN\\nALLGEMEINE ANGABEN\\n'\n",
      "Anzahl Chunks: 0\n",
      "Anzahl Tabellen: 1\n",
      "  Tabelle 1: Typ=<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "inspect_pages_data (pages_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15492671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Seiten in pages_data: 2\n",
      "Seite 0 keys: ['page_number', 'file_name', 'document_id', 'image_id', 'width', 'height', 'text', 'chunks', 'tables']\n",
      "Text länge: 766\n",
      "Tabellenanzahl: 1\n",
      "Erste Tabelle (head):\n",
      "  0                                                  1        2         3  \\\n",
      "0                                                                           \n",
      "1                                           Emissionen           N-1=2023   \n",
      "2                                Scope-i-THG-tmisionen                      \n",
      "3    Scope-1-THG-Bruttoemissionen (tCO,e) exklusive...  618.089      n.a.   \n",
      "4    Scope 1(tCO2e) aus Dampf, Wârme und Elektrizit...  360.792      n.a.   \n",
      "\n",
      "         4                                     5  \\\n",
      "0                                                  \n",
      "1   N=2024  Jahrlich% des Ziels/ Vorheriges Jahr   \n",
      "2                                                  \n",
      "3  405.621                                  n.a.   \n",
      "4                                           n.a.   \n",
      "\n",
      "                                         6     7     8     9  \n",
      "0                                                             \n",
      "1  Reduktion ggu. Basisjahr (9N/Basisjahr)  2025        2045  \n",
      "2                                                             \n",
      "3                                     n.a.  n.a.  n.a.  n.a.  \n",
      "4                                     n.a.  n.a.  n.a.  n.a.  \n",
      "Seite 1 keys: ['page_number', 'file_name', 'document_id', 'image_id', 'width', 'height', 'text', 'chunks', 'tables']\n",
      "Text länge: 1141\n",
      "Tabellenanzahl: 1\n",
      "Erste Tabelle (head):\n",
      "  0                                                  1               2  \\\n",
      "0                                                                        \n",
      "1    3Tâtigkeiteni im Zusammenhang mit Brenn- stoff...  Basisjahr 2021   \n",
      "2                                                                        \n",
      "3    4Vorgelagerter Transport und Vertrieb 5Abfalla...       1.096.389   \n",
      "4                                                                        \n",
      "\n",
      "          3        4                                     5  \\\n",
      "0                                                            \n",
      "1  N-1=2023           Jahrlich% des Ziels/ Vorheriges Jahr   \n",
      "2      n.a.  235.407                                  n.a.   \n",
      "3      n.a.  818.920                                  n.a.   \n",
      "4      n.a.                                                  \n",
      "\n",
      "                                         6     7     8     9  \n",
      "0                                                             \n",
      "1  Reduktion ggu. Basisjahr (%N/Basisjahr)  2025  2030  2045  \n",
      "2                                     n.a.  n.a.  n.a.  n.a.  \n",
      "3                                     n.a.  n.a.  n.a.  n.a.  \n",
      "4                                     n.a.        n.a.        \n"
     ]
    }
   ],
   "source": [
    "print(f\"Anzahl Seiten in pages_data: {len(pages_data)}\")\n",
    "for i, page in enumerate(pages_data):\n",
    "    print(f\"Seite {i} keys: {list(page.keys())}\")\n",
    "    print(f\"Text länge: {len(page['text'])}\")\n",
    "    print(f\"Tabellenanzahl: {len(page['tables'])}\")\n",
    "    if len(page['tables']) > 0:\n",
    "        print(f\"Erste Tabelle (head):\\n{page['tables'][0].head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c7b4ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_JSON = \"/repo/notebooks/json/extracted_pages_data.json\"  # Beispiel Pfad im Shared Volume\n",
    "export_pages_data_as_json (pages_data, OUTPUT_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c50958c-45cb-4ad6-8317-9d68af7452ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
